{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk8gq_FBlkQq"
      },
      "source": [
        "# Value Function Approximation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test if you can run this block\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5--INGLinIOO"
      },
      "source": [
        "## Review Numpy Inner Product\n",
        "Vectors: $\\mathbf{x}, \\mathbf{w}$\n",
        "\n",
        "Inner product: $\\mathbf{x}^\\top \\mathbf{w}$\n",
        "\n",
        "Let's create two np.array vectors x = [1,2] and w = [3,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFuuq4R-ljpa",
        "outputId": "3c1f2558-a21b-4c9f-835b-cd424f2dc2ec"
      },
      "outputs": [],
      "source": [
        "x = np.array([1, 2])\n",
        "w = np.array([3, 4])\n",
        "\n",
        "# Task: Compute the inner product of x and w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlGWlM2fnNRS"
      },
      "source": [
        "## Representing States with Feature Vectors\n",
        "Let's decide how we represent states using features.\n",
        "\n",
        "Define a function $x$ that maps a state to the corresponding feature vector\n",
        "\n",
        "$$x(S_1) = [1,1]$$\n",
        "$$x(S_2) = [2,1]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omi7PGxXpJso"
      },
      "source": [
        "## Approximating Value Function\n",
        "Now, instead of storing the value function $v$ in a table, let's parameterize $v$ with weight $\\mathbf{w}$.\n",
        "\n",
        "$$v(S,\\mathbf{w}) = x(S)^\\top \\mathbf{w}= \\sum_j x_j(S)\\mathbf{w}_j$$\n",
        "\n",
        "e.g. If $\\mathbf{w} = [1,1]$, the V value of state $S_1$ and $S_2$ are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeIOvMK5qaMw",
        "outputId": "7ba611a5-4975-4698-fa09-f9d8c053004c"
      },
      "outputs": [],
      "source": [
        "xs1 = np.array([1, 1])\n",
        "xs2 = np.array([2, 1])\n",
        "\n",
        "# Initialize w\n",
        "w = np.array([1, 1])\n",
        "\n",
        "# Compute the value of each state based on the current w\n",
        "def show_all_values(w):\n",
        "    pass\n",
        "    return [val_s1, val_s2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJfqm_vBq0V2"
      },
      "source": [
        "So if we change $\\mathbf{w}$, we can change the value function.\n",
        "\n",
        "But how do we choose a nice $\\mathbf{w}$ to have an accurate V values for all states?\n",
        "\n",
        "We want to approximate TRUE value function $v$. Assume a blackbox algorithm gave us the true value funcrion. For example, $v(S_1) = 4$, and $v(S_2) = 6$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qpFh328tPlp"
      },
      "source": [
        "----------------------------\n",
        "I think you can understand the benefits of function approx now, comparing it with the tabular method.\n",
        "1. Even when you visit a state (e.g. $S_1$), the value function of the other states is also updated (e.g. $S_2$).\n",
        "2. You can reduce memory to save the value function. Imagine you have 1 million states like $S_1$. If it's the tabular method, you need to store 1 million entries of $(s, v(s))$. If it's function approx, you only store two numbers $w = (w_1, w_2)$.\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7Tdb_jfZx8q",
        "outputId": "96ec3f9b-4f70-4565-805a-86494ebaba6c"
      },
      "outputs": [],
      "source": [
        "# Manually change w to a few different values and observe the difference in the value function\n",
        "w = \n",
        "\n",
        "print(show_all_values(w))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V_TWh3bZylt"
      },
      "source": [
        "So we know $\\mathbf{w}^* = [2,2]$ is the best parameter approximating $v$. \n",
        "\n",
        "Is there any way to find such $\\mathbf{w}^*$? The best $\\mathbf{w}^*$ should minimize the loss function:\n",
        "$$J(\\mathbf{w})=\\mathbb{E}\\left[\\left(v(S)-\\mathbf{x}(S)^{\\top} \\mathbf{w}\\right)^{2}\\right]$$\n",
        "This is becase, in the ideal scenario, $v(s) = \\mathbf{x}(S)^{\\top} \\mathbf{w}^*$\n",
        "\n",
        "Here, it is a simple minimization of function $J(\\mathbf{w})$. Therefore, we can use the gradient descent method to solve it.\n",
        "\n",
        "$$\\begin{aligned} \\mathbf{w} &\\gets \\mathbf{w}-\\frac{1}{2} \\alpha \\nabla_{\\mathbf{w}} J(\\mathbf{w}) \\\\ &= \\mathbf{w} + \\alpha \\left(v_{\\pi}(S)-\\hat{v}(S, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{v}(S, \\mathbf{w}) \\end{aligned}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we have $v(s) = \\mathbf{x}(S)^{\\top} \\mathbf{w}^*$, $$\\nabla_{\\mathbf{w}} \\hat{v}(S, \\mathbf{w}) = \\mathbf{x}(S).$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DP4bzp15b3g8"
      },
      "outputs": [],
      "source": [
        "def plotJs(Js, show_limit = 80):\n",
        "  plt.plot(range(0,show_limit), Js[0:show_limit], label='J')\n",
        "  plt.ylabel('Loss Function J')\n",
        "  plt.xlabel('Iteration Round')\n",
        "  plt.plot()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "-gzk6QKyeVVf",
        "outputId": "e202b1ed-838c-411d-d14c-f83cf06ea134"
      },
      "outputs": [],
      "source": [
        "num_iter = 4000\n",
        "\n",
        "# step size\n",
        "alpha = 0.02\n",
        "\n",
        "# assume an oracle gave us these values\n",
        "# in practice, we don't have the oracle. The details will be discussed later.\n",
        "true_vs1 = 4\n",
        "true_vs2 = 6\n",
        "\n",
        "# initialization\n",
        "w = np.array([1,1])\n",
        "\n",
        "Js = []\n",
        "\n",
        "for i in range(num_iter):\n",
        "  # we assume that an RL agent visits each state (s1, s2) uniformly randomly.\n",
        "  # this is not true for real scenarios since the agent uses a certain exploration strategy \n",
        "  \n",
        "\n",
        "  # compute the value of the visited state\n",
        "  # update w\n",
        "  w =\n",
        "  \n",
        "  # compute the loss (true - current)^2\n",
        "  J = \n",
        "\n",
        "  # record Js\n",
        "  Js.append(J)\n",
        "\n",
        "  # Print every 100 rounds\n",
        "  if i % 100 == 0:\n",
        "    print(f'w: {w}, J: {J}')\n",
        "\n",
        "print(f'Final w: {w}')\n",
        "plotJs(Js)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHs_r6iMkPPu"
      },
      "source": [
        "However, we do not know the true value function. (This was the motivation why we started learning RL.) \n",
        "\n",
        "What we have access to is sequences of $s, a, r, s^\\prime, ...$. We know how we can estimate the true $v$ using a lot of experiences by MC, TD, and other control methods!\n",
        "\n",
        "If it is MC, we can use return $G_t$ of an episode. We can simply replace the $v_{\\pi}(S)$ term in SGD with $G_t$.\n",
        "\n",
        "$$\\alpha\\left(G_t-\\hat{v}(S, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{v}(S, \\mathbf{w})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS1VvczzN6n6"
      },
      "source": [
        "For example, if it is MC:\n",
        "\n",
        "Instead of \n",
        "```\n",
        "  w = w + alpha * (true_vs - vs) * xs\n",
        "\n",
        "  J = pow(true_vs - vs, 2)\n",
        "\n",
        "```\n",
        "we will use\n",
        "```\n",
        "  w = w + alpha * (Gt - vs) * xs\n",
        "\n",
        "  J = pow(Gt - vs, 2)\n",
        "```\n",
        "\n",
        "As the accumulation of Gt estimates the true value funciton, it should approximate the targe\n",
        "\n",
        "\n",
        "(X is a terminal state.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa3Y4Rf_SN4z",
        "outputId": "6ef5f457-97d4-4419-a28b-126eb28fb3db"
      },
      "outputs": [],
      "source": [
        "# Assume that we only have two states S1 = (1,1) and S2 = (1,2)\n",
        "states = {'s1': np.array([1, 1]), 's2': np.array([1, 2])}\n",
        "\n",
        "\n",
        "# Let's think about a batch MC scenario given the following episodes\n",
        "episodes = [\n",
        "            [('s1', 'a1', '3.95'),],\n",
        "            [('s2', 'a2', '4'),],\n",
        "            [('s1', 'a2', '3.9'),],\n",
        "            [('s1', 'a1', '-1.4'), ('s2', 'a1', '6')],\n",
        "            [('s1', 'a2', '4.1'),],\n",
        "            [('s1', 'a3', '-1.2'), ('s2', 'a1', '5.8')],\n",
        "            [('s1', 'a2', '-1.6'), ('s2', 'a2', '6.1')],\n",
        "            [('s2', 'a3', '5.9'),],\n",
        "            [('s1', 'a4', '4'),],\n",
        "            [('s2', 'a4', '6'),]]\n",
        "\n",
        "gamma = 0.9\n",
        "S_IDX = 0\n",
        "R_IDX = 2\n",
        "alpha = 0.02\n",
        "\n",
        "num_iter = 100_000\n",
        "\n",
        "# initialization\n",
        "w = np.array([0,0])\n",
        "\n",
        "for round in range(num_iter):\n",
        "  # randomly pick one episode (replay buffer)\n",
        "  epi = random.choice(episodes)\n",
        "\n",
        "  # print(epi)\n",
        "  Gt = 0.0\n",
        "  for exp in reversed(epi):\n",
        "    # Compute the return\n",
        "    Gt = \n",
        "    \n",
        "    # Update w\n",
        "    w = \n",
        "\n",
        "  # Print every 100 episode\n",
        "  if round % 100 == 0:\n",
        "    J = pow(Gt - vs, 2)\n",
        "    # print(f'r{round} - w: {w}, J: {J}')\n",
        "\n",
        "print(f'Final w: {w}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 ('f22cs156')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f0af7ae92ff834062ca0e068eb4ad156659c9ba25dfa3969a903dfa92de8455"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
